{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmdIr9easj8K",
        "outputId": "a22de58e-e85e-4e0e-95e7-8cf19e7fac5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved 715 books successfully.\n",
            "Data saved to books_datas.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "link = \"https://www.googleapis.com/books/v1/volumes\"\n",
        "api = \"AIzaSyCwkD8WOJPxCeiU-dGSxDLLO3acod_6KzA\"\n",
        "\n",
        "# Fixed query for demonstration\n",
        "query = \"python\"\n",
        "\n",
        "books = []\n",
        "batch_size = 40  # Maximum allowed per request\n",
        "total_books = 2000  # Desired number of books (you can adjust this)\n",
        "start_index = 0  # Initialize starting index\n",
        "\n",
        "# Output file\n",
        "output_file = \"books_datas.csv\"\n",
        "\n",
        "try:\n",
        "    while len(books) < total_books:\n",
        "        # Send GET request with pagination\n",
        "        response = requests.get(link, params={\n",
        "            \"key\": api,\n",
        "            \"q\": query,\n",
        "            \"startIndex\": start_index,\n",
        "            \"maxResults\": batch_size\n",
        "        })\n",
        "\n",
        "        # Check if response status is OK\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse JSON content\n",
        "        data = response.json()\n",
        "\n",
        "        # Add items to books list if they exist\n",
        "        if \"items\" in data:\n",
        "            for item in data[\"items\"]:\n",
        "                volume_info = item.get(\"volumeInfo\", {})\n",
        "                sale_info = item.get(\"saleInfo\", {})\n",
        "                list_price = sale_info.get(\"listPrice\", {})\n",
        "                retail_price = sale_info.get(\"retailPrice\", {})\n",
        "\n",
        "                # Extract fields\n",
        "                book = {\n",
        "                    \"book_id\": item.get(\"id\", \"\"),\n",
        "                    \"search_key\": query,\n",
        "                    \"book_title\": volume_info.get(\"title\", \"\"),\n",
        "                    \"book_subtitle\": volume_info.get(\"subtitle\", \"\"),\n",
        "                    \"book_authors\": \", \".join(volume_info.get(\"authors\", [])),\n",
        "                    \"book_description\": volume_info.get(\"description\", \"\"),\n",
        "                    \"industryIdentifiers\": \", \".join([f\"{id_type['type']}:{id_type['identifier']}\" for id_type in volume_info.get(\"industryIdentifiers\", [])]),\n",
        "                    \"text_readingModes\": volume_info.get(\"readingModes\", {}).get(\"text\", False),\n",
        "                    \"image_readingModes\": volume_info.get(\"readingModes\", {}).get(\"image\", False),\n",
        "                    \"pageCount\": volume_info.get(\"pageCount\", 0),\n",
        "                    \"categories\": \", \".join(volume_info.get(\"categories\", [])),\n",
        "                    \"language\": volume_info.get(\"language\", \"\"),\n",
        "                    \"imageLinks\": volume_info.get(\"imageLinks\", {}).get(\"thumbnail\", \"\"),\n",
        "                    \"ratingsCount\": volume_info.get(\"ratingsCount\", 0),\n",
        "                    \"averageRating\": volume_info.get(\"averageRating\", 0),\n",
        "                    \"country\": sale_info.get(\"country\", \"\"),\n",
        "                    \"saleability\": sale_info.get(\"saleability\", \"\"),\n",
        "                    \"isEbook\": sale_info.get(\"isEbook\", False),\n",
        "                    \"amount_listPrice\": list_price.get(\"amount\", 0),\n",
        "                    \"currencyCode_listPrice\": list_price.get(\"currencyCode\", \"\"),\n",
        "                    \"amount_retailPrice\": retail_price.get(\"amount\", 0),\n",
        "                    \"currencyCode_retailPrice\": retail_price.get(\"currencyCode\", \"\"),\n",
        "                    \"buyLink\": sale_info.get(\"buyLink\", \"\"),\n",
        "                    \"year\": volume_info.get(\"publishedDate\", \"\").split(\"-\")[0],  # Extract year if available\n",
        "                    \"publisher\": volume_info.get(\"publisher\", \"\")  # Add publisher field\n",
        "                }\n",
        "\n",
        "                books.append(book)\n",
        "        else:\n",
        "            print(\"No more books available.\")\n",
        "            break\n",
        "\n",
        "        # Update starting index for the next batch\n",
        "        start_index += batch_size\n",
        "\n",
        "        # Stop if fewer books are returned than requested in the batch\n",
        "        if len(data.get(\"items\", [])) < batch_size:\n",
        "            break\n",
        "\n",
        "    print(f\"Retrieved {len(books)} books successfully.\")\n",
        "\n",
        "    # Write to CSV file\n",
        "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=books[0].keys())\n",
        "        writer.writeheader()\n",
        "        writer.writerows(books)\n",
        "\n",
        "    print(f\"Data saved to {output_file}\")\n",
        "\n",
        "except requests.exceptions.HTTPError as http_err:\n",
        "    print(f\"HTTP error occurred: {http_err}\")\n",
        "except requests.exceptions.JSONDecodeError as json_err:\n",
        "    print(f\"JSON decoding failed: {json_err}\")\n",
        "except Exception as err:\n",
        "    print(f\"An error occurred: {err}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table 'books_datas' created or already exists.\n",
            "Data from books_datas.csv inserted successfully into books_datas.\n"
          ]
        }
      ],
      "source": [
        "import psycopg2\n",
        "import csv\n",
        "\n",
        "# PostgreSQL credentials\n",
        "host = \"localhost\"\n",
        "user = \"postgres\"\n",
        "password = \"root\"\n",
        "database_name = \"project\"\n",
        "\n",
        "# CSV file path\n",
        "csv_file_path = \"books_datas.csv\"\n",
        "\n",
        "# PostgreSQL connection function\n",
        "def connect_to_db():\n",
        "    try:\n",
        "        conn = psycopg2.connect(\n",
        "            host=host,\n",
        "            user=user,\n",
        "            password=password,\n",
        "            dbname=database_name\n",
        "        )\n",
        "        return conn\n",
        "    except psycopg2.OperationalError as error:\n",
        "        print(f\"Error connecting to the database: {error}\")\n",
        "        return None\n",
        "\n",
        "# Create the table if it doesn't exist\n",
        "def create_table(conn):\n",
        "    create_table_query = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS books_datas (\n",
        "        book_id TEXT PRIMARY KEY,\n",
        "        search_key TEXT,\n",
        "        book_title TEXT,\n",
        "        book_subtitle TEXT,\n",
        "        book_authors TEXT,\n",
        "        book_description TEXT,\n",
        "        industryIdentifiers TEXT,\n",
        "        text_readingModes BOOLEAN,\n",
        "        image_readingModes BOOLEAN,\n",
        "        pageCount INTEGER,\n",
        "        categories TEXT,\n",
        "        language TEXT,\n",
        "        imageLinks TEXT,\n",
        "        ratingsCount INTEGER,\n",
        "        averageRating NUMERIC,\n",
        "        country TEXT,\n",
        "        saleability TEXT,\n",
        "        isEbook BOOLEAN,\n",
        "        amount_listPrice NUMERIC,\n",
        "        currencyCode_listPrice TEXT,\n",
        "        amount_retailPrice NUMERIC,\n",
        "        currencyCode_retailPrice TEXT,\n",
        "        buyLink TEXT,\n",
        "        year TEXT,\n",
        "        publisher TEXT\n",
        "    );\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with conn.cursor() as cur:\n",
        "            cur.execute(create_table_query)\n",
        "            conn.commit()\n",
        "            print(\"Table 'books_datas' created or already exists.\")\n",
        "    except Exception as error:\n",
        "        print(f\"Error creating table: {error}\")\n",
        "        conn.rollback()\n",
        "\n",
        "# Insert data from CSV into PostgreSQL\n",
        "def insert_csv_to_db(conn, csv_file):\n",
        "    table_name = \"books_datas\"  # Target table name\n",
        "    try:\n",
        "        with conn.cursor() as cur:\n",
        "            with open(csv_file, mode=\"r\", encoding=\"utf-8\") as file:\n",
        "                reader = csv.reader(file)\n",
        "                headers = next(reader)  # Read the header row\n",
        "                \n",
        "                # Prepare SQL query to match the columns in the table\n",
        "                query = f\"\"\"\n",
        "                    INSERT INTO {table_name} ({', '.join(headers)})\n",
        "                    VALUES ({', '.join(['%s'] * len(headers))})\n",
        "                    ON CONFLICT (book_id) DO NOTHING;  -- Avoid duplicates\n",
        "                \"\"\"\n",
        "\n",
        "                # Insert rows from the CSV file\n",
        "                for row in reader:\n",
        "                    cur.execute(query, row)\n",
        "                \n",
        "                # Commit the transaction\n",
        "                conn.commit()\n",
        "                print(f\"Data from {csv_file} inserted successfully into {table_name}.\")\n",
        "    except Exception as error:\n",
        "        print(f\"Error inserting data: {error}\")\n",
        "        conn.rollback()\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    conn = connect_to_db()\n",
        "    if conn:\n",
        "        try:\n",
        "            create_table(conn)  # Create table if not exists\n",
        "            insert_csv_to_db(conn, csv_file_path)  # Insert data from CSV\n",
        "        finally:\n",
        "            conn.close()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "871b5c4a235861420c4d07c89da82a644fd953e5440f6d988422c53357bd8e9e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
